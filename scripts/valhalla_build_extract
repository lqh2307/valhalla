#!/usr/bin/env python3

from typing import List, Tuple, Optional
from collections import namedtuple
from tarfile import BLOCKSIZE
from pathlib import Path
from io import BytesIO
from math import floor
from time import time
import argparse
import logging
import tarfile
import ctypes
import shutil
import struct
import sys

# "<" prefix: means little-endian and no alignment
INDEX_BIN_FORMAT = '<QLL'
INDEX_BIN_SIZE = struct.calcsize(INDEX_BIN_FORMAT)
INDEX_FILE = "index.bin"

# skip the first 40 bytes of the tile header
GRAPHTILE_SKIP_BYTES = struct.calcsize('<Q2f16cQ')

TRAFFIC_HEADER_FORMAT = '<2Q4I'
TRAFFIC_HEADER_SIZE = struct.calcsize(TRAFFIC_HEADER_FORMAT)
TRAFFIC_SPEED_SIZE = struct.calcsize('<Q')
TRAFFIC_VERSION = 3

Bbox = namedtuple("Bbox", "min_x min_y max_x max_y")
TILE_SIZES = {0: 4, 1: 1, 2: 0.25, 3: 0.25}

# hack so ArgumentParser can accept negative numbers
# see https://github.com/valhalla/valhalla/issues/3426
for i, arg in enumerate(sys.argv):
  if not len(arg) > 1:
    continue
  if (arg[0] == '-') and arg[1].isdigit():
    sys.argv[i] = ' ' + arg

class TileHeader(ctypes.Structure):
  """
  Resembles the uint64_t bit field at bytes 40 - 48 of the
  graphtileheader to get the directededgecount_.
  """

  _fields_ = [
    ("nodecount_", ctypes.c_ulonglong, 21),
    ("directededgecount_", ctypes.c_ulonglong, 21),
    ("predictedspeeds_count_", ctypes.c_ulonglong, 21),
    ("spare1_", ctypes.c_ulonglong, 1),
  ]

class TileResolver:
  def __init__(self, path: Path):
    """
    Abstraction so we don't have to care whether we're looking at a tile directory or tar file.

    Args:
      path: path to the tile directory or tar file.
    """
    self.path = path.resolve()
    self._is_tar = path.is_file()
    self._tar_obj: Optional[tarfile.TarFile] = tarfile.open(self.path, "r") if self._is_tar else None

    self.normalized_tile_paths: List[Path] = list()
    self.matched_paths: List[Path] = list()

    # pre-populate the available paths
    if self._is_tar:
      self.normalized_tile_paths = sorted(
        [Path(m.name) for m in self._tar_obj.getmembers() if m.name.endswith('.gph')]
      )
    else:
      self.normalized_tile_paths = sorted(
        p.relative_to(self.path) for p in self.path.rglob('*.gph')
      )

  def __del__(self):
    """Close the tar object on GC."""
    if self._tar_obj:
      self._tar_obj.close()

  def add_to_tar(self, tar: tarfile.TarFile):
    """Adds the self.matched_paths to the passed tar file."""
    # deduplicate the list (geojson variant might've added dups)
    # since 3.7 python dicts are insertion-ordered, so order is preserved
    for t in list(dict.fromkeys(self.matched_paths)):
      LOGGER.info(f"Adding tile {t} to the tar file")
      if self._is_tar:
        tar_member = self._tar_obj.getmember(str(t))
        tar.addfile(tar_member, self._tar_obj.extractfile(tar_member.name))
      else:
        tar.add(str(self.path.joinpath(t)), arcname=t)
        tar_member = tar.getmember(str(t))

# Config logs
LOGGER = logging.getLogger(__name__)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)5s: %(message)s"))
LOGGER.addHandler(handler)
LOGGER.setLevel(logging.INFO)

# Config args
parser = argparse.ArgumentParser(
  description="""Builds a tar extract from the tiles""",
)

parser.add_argument(
  "-p",
  "--prefix",
  help="Prefix of path to the data folders",
  type=Path,
  default="data",
)
parser.add_argument(
  "-t",
  "--with-traffic",
  help="Flag to add a traffic.tar skeleton",
  action="store_true",
  default=False,
)
parser.add_argument(
  "-d",
  "--delete-tiles",
  help="Delete all graph tiles",
  action="store_true",
  default=False,
)
parser.add_argument(
  "-b",
  "--bbox",
  help="If specified, will only archive tiles which are intersecting this bbox in the format 'minX,minY,maxX,maxY'",
  type=str,
)

def get_tile_bbox(tile_path_id: str) -> Tuple[float, float, float, float]:
  """Returns a tile's bounding box in minx,miny,maxx,maxy format"""
  try:
    level, tile_idx = [int(x.replace("/", "")) for x in get_tile_level_id(tile_path_id)]
  except ValueError:
    LOGGER.error(f"Couldn't get level and tile ID for tile {tile_path_id}")

    sys.exit(1)

  tile_size = TILE_SIZES[level]
  row = floor(tile_idx / (360 / tile_size))
  col = tile_idx % (360 / tile_size)

  tile_base_y = (row * tile_size) - 90
  tile_base_x = (col * tile_size) - 180

  return tile_base_x, tile_base_y, tile_base_x + tile_size, tile_base_y + tile_size

def get_tiles_with_bbox(tile_resolver_: TileResolver, bbox_str: str):
  """Returns all tile paths intersecting with the bbox"""
  try:
    bbox = Bbox(*[float(x) for x in bbox_str.split(",")])
  except ValueError:
    LOGGER.error(f"BBox {bbox_str} is not a comma-separated string of coordinates")

    sys.exit(1)

  # validate bbox
  if (bbox.min_x >= bbox.max_x or bbox.min_x < -180 or bbox.max_x > 180) or (
    bbox.min_y >= bbox.max_y or bbox.min_y < -90 or bbox.max_y > 90
  ):
    LOGGER.error(f"BBox invalid: {list(bbox)}")

    sys.exit(1)

  for tile_path in tile_resolver_.normalized_tile_paths:
    tile_bbox = Bbox(*get_tile_bbox(str(tile_path)))
    # check if tile_bbox is outside bbox
    if not any([
      tile_bbox.min_x < bbox.min_x and tile_bbox.max_x < bbox.min_x,  # left of bbox
      tile_bbox.min_y < bbox.min_y and tile_bbox.max_y < bbox.min_y,  # below bbox
      tile_bbox.min_x > bbox.max_x and tile_bbox.max_x > bbox.max_x,  # right of bbox
      tile_bbox.min_y > bbox.max_y and tile_bbox.max_y > bbox.max_y,  # above bbox
    ]):
      tile_resolver_.matched_paths.append(tile_path)

def get_tile_level_id(path: str) -> List[str]:
  """Returns both level and tile ID"""
  return path[:-4].split('/', 1)

def get_tile_id(path: str) -> int:
  """Turns a tile path into a numeric GraphId, including the level"""
  level, idx = get_tile_level_id(path)

  return int(level) | (int(idx.replace('/', '')) << 3)

def get_tar_info(name: str, size: int) -> tarfile.TarInfo:
  """Creates and returns a tarinfo object"""
  tarinfo = tarfile.TarInfo(name)
  tarinfo.size = size
  tarinfo.mtime = int(time())
  tarinfo.type = tarfile.REGTYPE

  return tarinfo

def write_index_to_tar(tar_fp_: Path):
  """Loop through all tiles and write the correct index.bin file to the tar"""
  # get the offset and size from the tarred tile members
  index: List[Tuple[int, int, int]] = list()
  with tarfile.open(tar_fp_, 'r|') as tar:
    for member in tar.getmembers():
      if member.name.endswith('.gph'):
        LOGGER.info(f"Tile {member.name} with offset: {member.offset_data}, size: {member.size}")

        index.append((member.offset_data, get_tile_id(member.name), member.size))

  # write back the actual index info
  with open(tar_fp_, 'r+b') as tar:
    # jump to the data block, index.bin is the first file
    tar.seek(BLOCKSIZE)
    for entry in index:
      tar.write(struct.pack(INDEX_BIN_FORMAT, *entry))

def create_extracts(traffic_extract_file_path: Path, do_traffic: bool, tile_resolver_: TileResolver, delete_tiles: bool):
  """Actually creates the tar ball. Break out of main function for testability."""
  tiles_count = len(tile_resolver_.matched_paths)

  if not tiles_count:
    LOGGER.error(f"Couldn't find usable tiles in {tile_resolver_.path}")

    sys.exit(1)

  # write the in-memory index file
  index_size = INDEX_BIN_SIZE * tiles_count
  index_fd = BytesIO(b'0' * index_size)
  index_fd.seek(0)

  tiles_extract_file_path = Path(f"{tile_resolver_.path}/tiles.tar")

  # first add the index file, then the sorted tiles to the tarfile
  # TODO: come up with a smarter strategy to cluster the tiles in the tar
  with tarfile.open(tiles_extract_file_path, 'w') as tar:
    tar.addfile(get_tar_info(INDEX_FILE, index_size), index_fd)
    tile_resolver_.add_to_tar(tar)

  write_index_to_tar(tiles_extract_file_path)

  if delete_tiles:
    if tile_resolver_.path.is_dir():
      for item in tile_resolver_.path.iterdir():
        if item.is_dir():
          shutil.rmtree(item)
        else:
          if item.name == "tiles.tar":
            continue
          else:
            item.unlink()

  LOGGER.info(f"Finished to tarring {tiles_count} tiles")

  # exit if no traffic extract wanted
  if not do_traffic:
    index_fd.close()

    sys.exit(0)

  LOGGER.info(f"Start creating traffic extract {traffic_extract_file_path}...")

  # we already have the right size of the index file, simply reset it
  index_fd.seek(0)
  with tarfile.open(tiles_extract_file_path) as tar_in, tarfile.open(traffic_extract_file_path, 'w') as tar_traffic:
    # this will let us do seeks
    in_fileobj = tar_in.fileobj

    # add the index file as first data
    tar_traffic.addfile(get_tar_info(INDEX_FILE, index_size), index_fd)
    index_fd.close()

    # loop over all routing tiles and create fixed-size traffic tiles
    # based on the directed edge count
    for tile_in in tar_in.getmembers():
      if not tile_in.name.endswith('.gph'):
        continue
      # jump to the data's offset and skip the uninteresting bytes
      in_fileobj.seek(tile_in.offset_data + GRAPHTILE_SKIP_BYTES)

      # read the appropriate size of bytes from the tar into the TileHeader struct
      tile_header = TileHeader()
      b = BytesIO(in_fileobj.read(ctypes.sizeof(TileHeader)))
      b.readinto(tile_header)
      b.close()

      # create the traffic header
      header_bytes = struct.pack(
        TRAFFIC_HEADER_FORMAT,
        get_tile_id(tile_in.name),  # numerical tile_id
        0,  # timestamp
        tile_header.directededgecount_,  # edge count
        TRAFFIC_VERSION,  # tile version
        0,  # spare2
        0,  # spare3
      )

      # create the traffic tile
      traffic_size = TRAFFIC_SPEED_SIZE * tile_header.directededgecount_
      tar_traffic.addfile(
        get_tar_info(tile_in.name, len(header_bytes) + traffic_size),
        BytesIO(header_bytes + b'\0' * traffic_size),
      )

      LOGGER.info(f"Traffic tile {tile_in.name} has {tile_header.directededgecount_} directed edges")

  write_index_to_tar(traffic_extract_file_path)

  LOGGER.info(f"Finished to creating the traffic extract {traffic_extract_file_path}")


if __name__ == '__main__':
  args = parser.parse_args()

  tile_resolver = TileResolver(Path(f"{args.prefix}/tiles"))

  if args.bbox:
    get_tiles_with_bbox(tile_resolver, args.bbox)
  else:
    tile_resolver.matched_paths = tile_resolver.normalized_tile_paths

  create_extracts(
    Path(f"{args.prefix}/traffic/traffic.tar"),
    args.with_traffic,
    tile_resolver,
    args.delete_tiles,
  )
